---
layout: post
title: "Backpropogation"
excerpt: "An introduction/overview to the backpropogation algorithm used for training neural networks"
tags: [DeepLearning, NueralNetworks, MachineLearning]
modified: 2015-10-18
comments: true
---
Like most folks in the computer vision and machine learning community, I've recently been using deep neural networks in my research. Deep learning has attracted huge amounts of interest recently as they have managed to achieve state-of-the-art results in many sub-domians of computer vision such as classification, localisation, segmentation and action recognition to name a few. Most notably, deep learning has recently been able to <a href = 'http://arxiv.org/pdf/1502.01852v1.pdf'>surpass human level performance</a> on the incredibbly difficult <a href = 'http://image-net.org/'>ImageNet challenge</a>. The beautiful thing about deep learning, is that these systems learn purely from the data, so called <i>end-to-end</i> learning.

<br />

During my quest to learn about deep learning, I found a lot of resources online describing how neural networks work at a high level, and even how to apply them to many problems. However, very few described how the learning occurs in detail and in particular very few went into depth of the back-propogation algorithm, it's extensions to convolutional neural networks (the most popular flavour) and how to check whether your computation of gradients is correct when coding this. The goal of this blog post is mostly to to act as a notebook for myself, for when I need a refresher on the derivation of backpropogation equations, but also to (hopefully) help anyone else who is trying to understand this (via google's wonderful indexing :)).

<br />

Before we discuss backpropogation, we have to discuss <i>gradient descent</i>. Gradient descent is an optimization algorithm used to find a loccal (or the global if you're lucky!) minimum of a function. In terms of machine learning, if we can express the goal of our algorithm with a <em>error</em> function (sometimes called a <em>cost</em> function), $E(x)$, then the global minimum of this function will give us the point of minimal error, which is exactly what we want our algorithm to achieve! 

<br />

To illustrate this, lets take the traditional example of simple linear regression i.e. fitting the line of best fit to some data. Let's assume we have the following data points $(y_i, x_i)$ as plotted below.
<img src="{{ site.url }}/images/data_points.png" alt="Data points (y, x)"/>
<center><em>Our dataset of points</em></center>
<br />
Recall that a straight line can be represeted by the formula $y = mx + b$, so given the data above we are trying to find the parameters $m$ and $b$ that best represent our data. To measure how well an estimate of $m$ and $b$ represent our data, we must define an error function, $E\left(m,b\right)$. In this example, we will use the average <em>sum of squared differences</em>, which essentially squares the error between the predicted value ($mx_i + b$) and the actual value ($y_i$), for each of the $N$ data points, $(y_i, x_i)$, in our dataset. More formally, $E(m,b)$ is defined as:
<center>
	$$
	E\left(m,b\right) = \frac{1}{N}\sum_{i=1}^{N}\big(y_i - \left(mx_i + b\right)\big)^2
	$$
</center> 
As our error function is only defined over 2 variables, we can visualize it for our data as shown below. As we can see there's an obvious global minimum on this surface around the point where $m = 5$ and $b = 3$, which is precisely the parameters used to generate the toy data points above. 
<img src="{{ site.url }}/images/error_surface.png" alt="The error surface generated using our data"/>
<center><em>The error surface of predictions, given our data</em></center>
<br />
The goal of gradient descent is to start on a random point on this error surface (a random $m$ and $b$) and find the minimum. From any point on the surface we can move towards the minimum by taking weighted steps in the <em>negative direction</em> of the gradient at that point. Recall that the gradient at a point is a vector, with the magnitude representing the slope and has the direction of the <em>greatest rate of increase</em> of the function. Therefore, starting at a point on the surface, to move towards the minimum we should move in the <em>negative direction</em> of the gradient at that point. This is precisely what gradient descent does. More formally, gradient descent is an iterative algorithm described by the following steps:
<ol>
	<li>use estimates of parameters w_i to estimate $\{a,a,a,a,b,b,b\}$ $f(x)$</li>
	<li>calcualte loss (error or cost)</li>
	<li>calculate derivates of with respect to $$w_i$$ </li>
	<li>update w_i with learning rate</li>
</ol>